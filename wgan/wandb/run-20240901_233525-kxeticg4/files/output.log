C:\Users\UMI\Desktop\myenv\Lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
C:\Users\UMI\Desktop\myenv\Lib\site-packages\keras\src\layers\activations\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.
  warnings.warn(
C:\Users\UMI\Desktop\myenv\Lib\site-packages\keras\src\layers\reshaping\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x00000227B2AB7D80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x00000227B2AB7D80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Loading weights from checkpoint: checkpoints\wgan_generator_weights_epoch_2000.weights.h5
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 63ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 17ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
Epoch 2000/10000 - D Loss: -0.41012632846832275 - G Loss: [array(-0.9768721, dtype=float32), array(-0.9768721, dtype=float32)]
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 5ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
Epoch 2001/10000 - D Loss: -2.8279972076416016 - G Loss: [array(-2.8254652, dtype=float32), array(-2.8254652, dtype=float32)]
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 18ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 15ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 10ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 0s/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
Epoch 2002/10000 - D Loss: -3.994222640991211 - G Loss: [array(-4.6859384, dtype=float32), array(-4.6859384, dtype=float32)]
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 13ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 25ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
Epoch 2003/10000 - D Loss: -3.8236522674560547 - G Loss: [array(-6.6055007, dtype=float32), array(-6.6055007, dtype=float32)]
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 15ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
Epoch 2004/10000 - D Loss: -1.6193351745605469 - G Loss: [array(-8.634998, dtype=float32), array(-8.634998, dtype=float32)]
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 13ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 15ms/step
Epoch 2005/10000 - D Loss: 4.468975067138672 - G Loss: [array(-10.676668, dtype=float32), array(-10.676668, dtype=float32)]
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 20ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 0s/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
Epoch 2006/10000 - D Loss: 13.231616973876953 - G Loss: [array(-12.6991415, dtype=float32), array(-12.6991415, dtype=float32)]
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 17ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 15ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
Epoch 2007/10000 - D Loss: 25.745502471923828 - G Loss: [array(-14.792101, dtype=float32), array(-14.792101, dtype=float32)]
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 14ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 22ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 10ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 13ms/step
Traceback (most recent call last):
  File "C:\Users\UMI\Desktop\wgan\wgan.py", line 151, in <module>
    train_wgan()
  File "C:\Users\UMI\Desktop\wgan\wgan.py", line 106, in train_wgan
    d_loss_real = discriminator.train_on_batch(real_images, -np.ones((batch_size, 1)))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\UMI\Desktop\myenv\Lib\site-packages\keras\src\backend\tensorflow\trainer.py", line 551, in train_on_batch
    logs = self.train_function(data())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\UMI\Desktop\myenv\Lib\site-packages\tensorflow\python\util\traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\UMI\Desktop\myenv\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py", line 833, in __call__
    result = self._call(*args, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\UMI\Desktop\myenv\Lib\site-packages\tensorflow\python\eager\polymorphic_function\polymorphic_function.py", line 878, in _call
    results = tracing_compilation.call_function(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\UMI\Desktop\myenv\Lib\site-packages\tensorflow\python\eager\polymorphic_function\tracing_compilation.py", line 139, in call_function
    return function._call_flat(  # pylint: disable=protected-access
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\UMI\Desktop\myenv\Lib\site-packages\tensorflow\python\eager\polymorphic_function\concrete_function.py", line 1322, in _call_flat
    return self._inference_function.call_preflattened(args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\UMI\Desktop\myenv\Lib\site-packages\tensorflow\python\eager\polymorphic_function\atomic_function.py", line 216, in call_preflattened
    flat_outputs = self.call_flat(*args)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\UMI\Desktop\myenv\Lib\site-packages\tensorflow\python\eager\polymorphic_function\atomic_function.py", line 251, in call_flat
    outputs = self._bound_context.call_function(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\UMI\Desktop\myenv\Lib\site-packages\tensorflow\python\eager\context.py", line 1552, in call_function
    outputs = execute.execute(
              ^^^^^^^^^^^^^^^^
  File "C:\Users\UMI\Desktop\myenv\Lib\site-packages\tensorflow\python\eager\execute.py", line 53, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Epoch 2008/10000 - D Loss: 40.91877746582031 - G Loss: [array(-16.777111, dtype=float32), array(-16.777111, dtype=float32)]
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 18ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step
Epoch 2009/10000 - D Loss: 60.06560134887695 - G Loss: [array(-18.846174, dtype=float32), array(-18.846174, dtype=float32)]
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 15ms/step
[1m1/1[22m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [1m0s[22m 16ms/step